{"cells":[{"cell_type":"markdown","metadata":{"id":"P0FrnfMcAsrr"},"source":["# Imports and Setup"]},{"cell_type":"markdown","metadata":{"id":"d1FIpkfB6Y-R"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2C8V1skstgvC","outputId":"9fc04ad1-95e7-43e7-b9ef-1f51a16f276d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Installing requirements\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jupyter>=1.0.0\n","  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n","Collecting K3D>=2.9.4\n","  Downloading k3d-2.15.2-py3-none-any.whl (23.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting matplotlib>=3.4.1\n","  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trimesh>=3.9.14\n","  Downloading trimesh-3.18.3-py3-none-any.whl (671 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 KB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.13.1+cu116)\n","Collecting pytorch-lightning>=1.2.8\n","  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-image>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (0.18.3)\n","Collecting pyrender>=0.1.43\n","  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting moviepy>=1.0.3\n","  Downloading moviepy-1.0.3.tar.gz (388 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 KB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pillow>=7.2.0\n","  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (4.64.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (1.7.3)\n","Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (1.21.6)\n","Collecting qtconsole\n","  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (6.1.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (5.3.4)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (5.6.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (7.7.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (5.7.16)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.8/dist-packages (from K3D>=2.9.4->-r requirements.txt (line 2)) (5.7.1)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from K3D>=2.9.4->-r requirements.txt (line 2)) (1.0.4)\n","Collecting traittypes\n","  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (23.0)\n","Collecting contourpy>=1.0.1\n","  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fonttools>=4.22.0\n","  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.1->-r requirements.txt (line 5)) (4.4.0)\n","Collecting lightning-utilities>=0.4.2\n","  Downloading lightning_utilities-0.6.0.post0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (6.0)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (2023.1.0)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (2.9.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (2023.1.23.1)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pyrender>=0.1.43->-r requirements.txt (line 8)) (1.15.0)\n","Collecting PyOpenGL==3.1.0\n","  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pyglet>=1.4.10\n","  Downloading pyglet-2.0.4-py3-none-any.whl (831 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.0/831.0 KB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting freetype-py\n","  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.9/978.9 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 9)) (4.4.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 9)) (2.25.1)\n","Collecting proglog<=1.0.0\n","  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n","Collecting imageio_ffmpeg>=0.2.0\n","  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (3.8.3)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.0.5)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.6.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (7.9.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.0.4)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.1.12)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.6.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.10)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.11.3)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.4)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.2.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.0.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.6.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.5.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.4)\n","Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.7.3)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.16.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.13.3)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (23.2.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.8.0)\n","Collecting qtpy>=2.0.1\n","  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (6.0.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (22.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (1.8.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (1.3.3)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (4.0.2)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (57.4.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.1)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.6.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.16.2)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.6)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.5.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.3)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.10.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.19.3)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.12.0)\n","Building wheels for collected packages: PyOpenGL, moviepy\n","  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745210 sha256=8de9ea583c3f386f90c63a57b270a5501caa937b8add67581d8b080f633d9bb9\n","  Stored in directory: /root/.cache/pip/wheels/85/ff/54/41f30bb227befd3dde302de39f9ba042589e8b4f93723107f2\n","  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110742 sha256=56fff2fe9fccafa957f993ee069de6073119d08097617da99ab6c2afb2d5879c\n","  Stored in directory: /root/.cache/pip/wheels/e4/a4/db/0368d3a04033da662e13926594b3a8cf1aa4ffeefe570cfac1\n","Successfully built PyOpenGL moviepy\n","Installing collected packages: PyOpenGL, pyglet, trimesh, traittypes, qtpy, proglog, pillow, lightning-utilities, jedi, imageio_ffmpeg, freetype-py, fonttools, contourpy, torchmetrics, matplotlib, pyrender, moviepy, qtconsole, pytorch-lightning, K3D, jupyter\n","  Attempting uninstall: PyOpenGL\n","    Found existing installation: PyOpenGL 3.1.6\n","    Uninstalling PyOpenGL-3.1.6:\n","      Successfully uninstalled PyOpenGL-3.1.6\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Attempting uninstall: moviepy\n","    Found existing installation: moviepy 0.2.3.5\n","    Uninstalling moviepy-0.2.3.5:\n","      Successfully uninstalled moviepy-0.2.3.5\n","Successfully installed K3D-2.15.2 PyOpenGL-3.1.0 contourpy-1.0.7 fonttools-4.38.0 freetype-py-2.3.0 imageio_ffmpeg-0.4.8 jedi-0.18.2 jupyter-1.0.0 lightning-utilities-0.6.0.post0 matplotlib-3.6.3 moviepy-1.0.3 pillow-9.4.0 proglog-0.1.10 pyglet-2.0.4 pyrender-0.1.45 pytorch-lightning-1.9.0 qtconsole-5.4.0 qtpy-2.3.0 torchmetrics-0.11.1 traittypes-0.2.1 trimesh-3.18.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","matplotlib","mpl_toolkits"]}}},"metadata":{},"output_type":"display_data"}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# We assume you uploaded the exercise folder in root Google Drive folder\n","!cp -r /content/drive/MyDrive/3d-lmnet-pytorch 3d-lmnet-pytorch\n","os.chdir('/content/drive/MyDrive/3d-lmnet-pytorch')\n","print('Installing requirements')\n","!pip install -r requirements.txt\n","\n","# Make sure you restart runtime when directed by Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jmMRX90tj2P","outputId":"0b582f36-8925-4804-c3c1-4efd80cb447c"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA availability: True\n"]}],"source":["import os\n","import sys\n","import torch\n","os.chdir('/content/3d-lmnet-pytorch/3d-lmnet-pytorch')\n","sys.path.insert(1, \"/content/3d-lmnet-pytorch/3d-lmnet-pytorch\")\n","print('CUDA availability:', torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXCyGAKZtrLd"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","from pathlib import Path\n","import numpy as np\n","import matplotlib as plt\n","import k3d\n","import trimesh\n","import torch\n","import skimage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mlePuTzttf0","outputId":"db40bca6-2086-439d-b725-de7036f9fa89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/download.html\n","Collecting pytorch3d\n","  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/pytorch3d-0.7.2-cp38-cp38-linux_x86_64.whl (72.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting iopath\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.21.6)\n","Collecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.2.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (9.4.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.4.0)\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=aea4a105f3c329731b4ab7a94436345bdbee52f98c31d3de914a9eae6a40839e\n","  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=151402de3577e7ee4431f2a439b319c984b0f5f370ee4d7851de3e12a34367c9\n","  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore, pytorch3d\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 pytorch3d-0.7.2 yacs-0.1.8\n"]}],"source":["torch.cuda.is_available()\n","need_pytorch3d=False\n","try:\n","    import pytorch3d\n","except ModuleNotFoundError:\n","    need_pytorch3d=True\n","if need_pytorch3d:\n","    if sys.platform.startswith(\"linux\"):\n","        # We try to install PyTorch3D via a released wheel.\n","        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n","        version_str=\"\".join([\n","            f\"py3{sys.version_info.minor}_cu\",\n","            torch.version.cuda.replace(\".\",\"\"),\n","            f\"_pyt{pyt_version_str}\"\n","        ])\n","        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n","    else:\n","        # We try to install PyTorch3D from source.\n","        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n","        !tar xzf 1.10.0.tar.gz\n","        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n","        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"]},{"cell_type":"markdown","metadata":{"id":"rxKfykIdzj3h"},"source":["## Download Datasets"]},{"cell_type":"markdown","metadata":{"id":"zUT-2sxV3ojS"},"source":["### ShapeNet Terms and Conditions\n","\n","In order to be able to use the data, we agree the below terms and conditions:\n","\n","1. Researcher shall use the Database only for non-commercial research and educational purposes.\n","2. Princeton University and Stanford University make no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose.\n","3. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify Princeton University and Stanford University, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted 3D models that he or she may create from the Database.\n","4. Researcher may provide research associates and colleagues with access to the Database provided that they first agree to be bound by these terms and conditions.\n","5. Princeton University and Stanford University reserve the right to terminate Researcher's access to the Database at any time.\n","6. If Researcher is employed by a for-profit, commercial entity, Researcher's employer shall also be bound by these terms and conditions, and Researcher hereby represents that he or she is fully authorized to enter into this agreement on behalf of such employer.\n","7. The law of the State of New Jersey shall apply to all disputes under this agreement."]},{"cell_type":"markdown","metadata":{"id":"aU6UFVmB2sDw"},"source":["### Unzip ShapeNet pointcloud zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHN_mJLtJYkz"},"outputs":[],"source":["!unzip -q ./data/ShapeNet_pointclouds.zip -d ./data"]},{"cell_type":"markdown","metadata":{"id":"gnY06WQ92yzn"},"source":["### Download 2D images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGwtTRnW40w_","outputId":"105f3a1b-7f97-4897-b022-b756fad9b90c"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-02-04 19:37:43--  http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Resolving cvgl.stanford.edu (cvgl.stanford.edu)... 171.64.64.64\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz [following]\n","--2023-02-04 19:37:43--  https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12318245442 (11G) [application/x-gzip]\n","Saving to: ‘./data/ShapeNetRendering.tgz’\n","\n","ShapeNetRendering.t 100%[===================>]  11.47G  14.4MB/s    in 14m 38s \n","\n","2023-02-04 19:52:22 (13.4 MB/s) - ‘./data/ShapeNetRendering.tgz’ saved [12318245442/12318245442]\n","\n"]}],"source":["!wget http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz -P ./data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdDWzJHLAcDz"},"outputs":[],"source":["!tar -xf ./data/ShapeNetRendering.tgz -C ./data\n","#!rm /content/term-project/data/ShapeNetRendering.tgz"]},{"cell_type":"markdown","metadata":{"id":"9WpwE3tS22bA"},"source":["### Construct ShapeNet dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKdGd1kvv7ub","outputId":"86d208aa-8f8d-4e18-8e91-cc81a52aba7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset is prepared for 2D model and variant 1:\n","Length of train set: 630504\n","Length of val set: 210192\n","Length of test set: 210120\n","Dataset is prepared for 2D model and variant 2 (only chair class):\n","Length of train set: 97608\n","Length of val set: 32544\n","Length of test set: 32520\n","Dataset is prepared for 3D autoencoder:\n","Length of train set: 26271\n","Length of val set: 8758\n","Length of test set: 8755\n"]}],"source":["from data.shapenet import ShapeNet\n","\n","# Create a dataset with train split\n","train_dataset = ShapeNet('train',image_model=True)\n","val_dataset = ShapeNet('valid',image_model=True)\n","test_dataset = ShapeNet('test',image_model=True)\n","\n","print(\"Dataset is prepared for 2D model and variant 1:\")\n","print(f'Length of train set: {len(train_dataset)}') \n","print(f'Length of val set: {len(val_dataset)}') \n","print(f'Length of test set: {len(test_dataset)}')  \n","\n","# Create a dataset with train split\n","train_dataset = ShapeNet('train',image_model=True,cat=1)\n","val_dataset = ShapeNet('valid',image_model=True,cat=1)\n","test_dataset = ShapeNet('test',image_model=True,cat=1)\n","\n","print(\"Dataset is prepared for 2D model and variant 2 (only chair class):\")\n","print(f'Length of train set: {len(train_dataset)}') \n","print(f'Length of val set: {len(val_dataset)}') \n","print(f'Length of test set: {len(test_dataset)}')  \n","\n","train_dataset = ShapeNet('train')\n","val_dataset = ShapeNet('valid')\n","test_dataset = ShapeNet('test')\n","\n","print(\"Dataset is prepared for 3D autoencoder:\")\n","print(f'Length of train set: {len(train_dataset)}') \n","print(f'Length of val set: {len(val_dataset)}') \n","print(f'Length of test set: {len(test_dataset)}')  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-enEihrj4z-T","outputId":"237c05f3-4071-4ca7-b477-e4fb85c41a1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input images: (3, 128, 128)\n","Input point cloud: (2048, 3)\n"]}],"source":["train_sample = train_dataset[1]\n","print(f'Input images: {train_sample[\"img\"].shape}')  \n","print(f'Input point cloud: {train_sample[\"point\"].shape}')  "]},{"cell_type":"markdown","metadata":{"id":"_s5meRr62_S1"},"source":["### Print output shape of the 2D Encoder model (both variational and normal versions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5zhCIIZlEui","outputId":"19505e70-7327-490d-a951-be667aaf2239"},"outputs":[{"name":"stdout","output_type":"stream","text":["input size: torch.Size([1, 3, 128, 128])\n","Mu size: torch.Size([1, 512]) Std size: torch.Size([1, 512])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 128, 128]             896\n","              ReLU-2         [-1, 32, 128, 128]               0\n","            Conv2d-3         [-1, 32, 128, 128]           9,248\n","              ReLU-4         [-1, 32, 128, 128]               0\n","            Conv2d-5           [-1, 64, 63, 63]          18,496\n","              ReLU-6           [-1, 64, 63, 63]               0\n","            Conv2d-7           [-1, 64, 63, 63]          36,928\n","              ReLU-8           [-1, 64, 63, 63]               0\n","            Conv2d-9           [-1, 64, 63, 63]          36,928\n","             ReLU-10           [-1, 64, 63, 63]               0\n","           Conv2d-11          [-1, 128, 31, 31]          73,856\n","             ReLU-12          [-1, 128, 31, 31]               0\n","           Conv2d-13          [-1, 128, 31, 31]         147,584\n","             ReLU-14          [-1, 128, 31, 31]               0\n","           Conv2d-15          [-1, 128, 31, 31]         147,584\n","             ReLU-16          [-1, 128, 31, 31]               0\n","           Conv2d-17          [-1, 256, 15, 15]         295,168\n","             ReLU-18          [-1, 256, 15, 15]               0\n","           Conv2d-19          [-1, 256, 15, 15]         590,080\n","             ReLU-20          [-1, 256, 15, 15]               0\n","           Conv2d-21          [-1, 256, 15, 15]         590,080\n","             ReLU-22          [-1, 256, 15, 15]               0\n","           Conv2d-23            [-1, 512, 7, 7]       1,180,160\n","             ReLU-24            [-1, 512, 7, 7]               0\n","           Conv2d-25            [-1, 512, 7, 7]       2,359,808\n","             ReLU-26            [-1, 512, 7, 7]               0\n","           Conv2d-27            [-1, 512, 7, 7]       2,359,808\n","             ReLU-28            [-1, 512, 7, 7]               0\n","           Conv2d-29            [-1, 512, 7, 7]       2,359,808\n","             ReLU-30            [-1, 512, 7, 7]               0\n","           Conv2d-31            [-1, 512, 2, 2]       6,554,112\n","             ReLU-32            [-1, 512, 2, 2]               0\n","           Linear-33                  [-1, 512]       1,049,088\n","           Linear-34                  [-1, 512]       1,049,088\n","================================================================\n","Total params: 18,858,720\n","Trainable params: 18,858,720\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.19\n","Forward/backward pass size (MB): 37.47\n","Params size (MB): 71.94\n","Estimated Total Size (MB): 109.59\n","----------------------------------------------------------------\n","Latent shape: torch.Size([1, 512])\n"]}],"source":["from model.model_2d import ImageEncoder\n","from torchsummary import summary\n","\n","model2d_variational=ImageEncoder(\"variational\",512)\n","model2d_variational.cuda()\n","input_tensor = torch.randn(1,3,128,128)\n","input_tensor=input_tensor.cuda()\n","print(\"input size: \",input_tensor.size())\n","\n","\n","mu,std = model2d_variational(input_tensor)\n","print(\"Mu size: \", mu.size(),\", Std size: \", std.size())\n","summary(model2d_variational,(3,128,128))\n","model2d_normal=ImageEncoder(\"normal\",512)\n","model2d_normal.cuda()\n","latent=model2d_normal(input_tensor)\n","print(\"Latent shape: \",latent.size())"]},{"cell_type":"markdown","metadata":{"id":"B28DA-Zp9Su8"},"source":["# 3D Point Cloud Autoencoder Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"43FQyYb9-XJE"},"outputs":[],"source":["from training import train_ae\n","\n","config = {\n","    'root': './3d-lmnet-pytorch/',\n","    'experiment_name': '3d_autoencoder',\n","    'device': 'cuda:0', \n","    'npoints': 2048,\n","    'mpoints': 2025,\n","    'lr': 1e-4,\n","    \"autoencoder\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_300.pth\",\n","    \"3d_ae_gt\": \"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/imgs/gt/\",\n","    \"3d_ae_pred\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/imgs/pred/\",\n","    'weight_decay': 1e-6,\n","    'bottleneck': 512,\n","    'batch_size': 32,\n","    'resume_ckpt': None,\n","    'learning_rate_model':  0.00005,\n","    'max_epochs': 200,  \n","    'num_workers': 4,\n","    \"input_size\" : 256,\n","    \"hidden_size\" : 256,\n","    \"output_size\" : 2048*3,\n","    'log_dir': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches',\n","    'print_every_n': 5,\n","    'visualize_every_n': 5,\n","}\n","\n","train_ae.main(config)"]},{"cell_type":"markdown","metadata":{"id":"XhQwt86S3KLX"},"source":["# Train 2D Encoder \n","Train 2D Image Encoder model to match the predicted latent space to the output of 3D Encoder of pointclouds"]},{"cell_type":"markdown","metadata":{"id":"uvuWag580_fw"},"source":["## Variant I - Latent Matching with L1 Loss"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1675606429047,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"H5AfhbLEnbIt"},"outputs":[],"source":["from training import train_2d_to_3d\n","\n","config = {\n","    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L1',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'bottleneck': 512,\n","    \"cat\":13,\n","    'batch_size': 32,\n","    \"loss_criterion\":\"L1\",\n","    \"final_layer\":\"normal\",\n","    \"3d_autoencoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'resume_ckpt': None,\n","    'learning_rate_model':  5e-5,\n","    'max_epochs': 30,  \n","    'save_every_n': 1,\n","    'validate_every_n': 3,\n","    \"autoencoder_bottleneck\":512,\n","    \"autoencoder_hidden_size\":256,\n","    \"autoencoder_output_size\":2048*3,\n","}\n","\n","train_2d_to_3d.main(config)"]},{"cell_type":"markdown","metadata":{"id":"0UT6VzUJ1TKB"},"source":["## Variant I - Latent Matching with L2 Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHNSisYe1VFg"},"outputs":[],"source":["from training import train_2d_to_3d\n","\n","config = {\n","    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L2',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'bottleneck': 512,\n","    \"cat\":13,\n","    'batch_size': 32,\n","    \"loss_criterion\":\"L2\",\n","    \"final_layer\":\"normal\",\n","    \"3d_autoencoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'resume_ckpt': \"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L2/model_epoch_new_relu_L2_14.pth\",\n","    'learning_rate_model':  5e-5,\n","    'max_epochs': 30,  \n","    'save_every_n': 1,\n","    'validate_every_n': 5,\n","    \"autoencoder_bottleneck\":512,\n","    \"autoencoder_hidden_size\":256,\n","    \"autoencoder_output_size\":2048*3,\n","}\n","\n","train_2d_to_3d.main(config)"]},{"cell_type":"markdown","metadata":{"id":"cVjsNa1N1px7"},"source":["## Variant II - Probabilistic Latent Matching"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xv-oEiXO1r0F"},"outputs":[],"source":["from training import train_2d_to_3d\n","\n","config = {\n","    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/diversity/NEW',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'bottleneck': 512,\n","    \"cat\":1,\n","    'batch_size': 32,\n","    \"loss_criterion\":\"variational\",\n","    \"final_layer\":\"variational\",\n","    \"3d_autoencoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'resume_ckpt': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/diversity/NEW/model_epoch_10.pth',\n","    'learning_rate_model':  5e-5,\n","    'max_epochs': 20,  \n","    'save_every_n': 1,\n","    'validate_every_n': 3,\n","    \"autoencoder_bottleneck\":512,\n","    \"autoencoder_hidden_size\":256,\n","    \"autoencoder_output_size\":2048*3,\n","    \"alpha\":0.2,\n","    \"penalty_angle\":20,\n","    \"lambda\":5.5\n","}\n","\n","train_2d_to_3d.main(config)"]},{"cell_type":"markdown","metadata":{"id":"BMfuS_dL3T-A"},"source":["# Inference\n","Infer pointclouds using the trained 2D Image Encoder and 3D Pointcloud Decoder models"]},{"cell_type":"markdown","metadata":{"id":"xa-wqJSr3hk-"},"source":["## Variant I - Inferences"]},{"cell_type":"markdown","metadata":{"id":"G4iWoRro2RBv"},"source":["### 2D Image Encoder with L1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qRDWqdt1vZ5d","outputId":"a748b37a-1c84-48cf-d85a-d3680af0176c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda:0\n"," initial input 512 initial hidden 256 initial output 6144\n","Length of test datsaset: 210120\n","Total test chamfer distance: tensor(0.0049)\n"]}],"source":["from inference import inference_2d_to_3d \n","\n","config = {\n","    'encoder_path': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L1/model_epoch_new_relu_L1_30.pth',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'bottleneck': 512,\n","    \"2d_inference_pred\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_normal_L1/pred/\",\n","    \"2d_inference_gt_point\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_normal_L1/gt/pointcloud/\",\n","    \"2d_inference_gt_img\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_normal_L1/gt/image/\",\n","    \"cat\":13,\n","    'batch_size': 1,\n","    \"loss_criterion\":\"L1\",\n","    \"final_layer\":\"normal\",\n","    \"3d_autoencoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'resume_ckpt': None,\n","    'learning_rate_model':  5e-5,\n","    \"autoencoder_bottleneck\":512,\n","    \"autoencoder_hidden_size\":256,\n","    \"autoencoder_output_size\":2048*3\n","\n","}\n","inference_2d_to_3d.main(config)"]},{"cell_type":"markdown","metadata":{"id":"9-8C7ogL2Typ"},"source":["### 2D Image Encoder with L2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4I2gY2Ai2W7e"},"outputs":[],"source":["from inference import inference_2d_to_3d \n","\n","config = {\n","    'encoder_path': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L2/model_epoch__new_relu_L2_30.pth',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'bottleneck': 512,\n","    \"2d_inference_pred\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_normal_L2/pred/\",\n","    \"2d_inference_gt_point\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_normal_L2/gt/pointcloud/\",\n","    \"2d_inference_gt_img\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_normal_L2/gt/image/\",\n","    \"cat\":13,\n","    'batch_size': 1,\n","    \"loss_criterion\":\"L2\",\n","    \"final_layer\":\"normal\",\n","    \"3d_autoencoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'resume_ckpt': None,\n","    'learning_rate_model':  5e-5,\n","    \"autoencoder_bottleneck\":512,\n","    \"autoencoder_hidden_size\":256,\n","    \"autoencoder_output_size\":2048*3\n","\n","}\n","inference_2d_to_3d.main(config)"]},{"cell_type":"markdown","metadata":{"id":"zJtbYMIm9CsE"},"source":["## Variant II - Inferences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_9zyepD9FG2"},"outputs":[],"source":["from inference import inference_2d_to_3d \n","\n","config = {\n","    'encoder_path': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/variational/model_epoch_30.pth',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'is_overfit': False,\n","    'bottleneck': 512,\n","    \"2d_inference_gt_point\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_variational/gt/pointcloud/\",\n","    \"2d_inference_gt_img\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_variational/gt/image/\",\n","    \"2d_inference_pred\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_to_3d_generation_variational/pred\",\n","    \"cat\":1,\n","    'batch_size': 1,\n","    \"loss_criterion\":\"variational\",\n","    \"final_layer\":\"variational\",\n","    \"3d_autoencoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'resume_ckpt': None,\n","    'learning_rate_model':  5e-5,\n","    \"autoencoder_bottleneck\":512,\n","    \"autoencoder_hidden_size\":256,\n","    \"autoencoder_output_size\":2048*3\n","}\n","inference_2d_to_3d.main(config)"]},{"cell_type":"markdown","metadata":{"id":"V4LmVnAu2jeS"},"source":["## 3D Point Cloud Inferences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoaKVSVfgnMc"},"outputs":[],"source":["from inference import infer_3d\n","\n","config = {\n","    \"autoencoder\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    \"infer_gt\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/ae_infer_results_3d/gt/\",\n","    \"infer_pred\": \"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/ae_infer_results_3d/pred/\",\n","    'bottleneck': 512,\n","    'batch_size': 1,\n","    'num_workers': 4,\n","    \"input_size\" : 256,\n","    \"hidden_size\" : 256,\n","    \"output_size\" : 2048*3,\n","}\n","infer_3d.main(config)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["P0FrnfMcAsrr","d1FIpkfB6Y-R","aU6UFVmB2sDw","gnY06WQ92yzn","9WpwE3tS22bA","B28DA-Zp9Su8","XhQwt86S3KLX","uvuWag580_fw","0UT6VzUJ1TKB","cVjsNa1N1px7","BMfuS_dL3T-A","G4iWoRro2RBv","9-8C7ogL2Typ","zJtbYMIm9CsE","V4LmVnAu2jeS"],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"1a453b615765addad4971118d8a9ab96c4ea1423c3e71d4bd1e873af4a20b25f"}}},"nbformat":4,"nbformat_minor":0}
