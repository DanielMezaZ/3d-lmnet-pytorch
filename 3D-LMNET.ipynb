{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2C8V1skstgvC"},"outputs":[],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# We assume you uploaded the exercise folder in root Google Drive folder\n","!cp -r /content/drive/MyDrive/3d-lmnet-pytorch 3d-lmnet-pytorch\n","os.chdir('/content/drive/MyDrive/3d-lmnet-pytorch')\n","print('Installing requirements')\n","!pip install -r requirements.txt\n","\n","# Make sure you restart runtime when directed by Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3352,"status":"ok","timestamp":1673190656119,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"9jmMRX90tj2P","outputId":"7d4e611e-4117-496b-ad50-28801d52f974"},"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA availability: True\n"]}],"source":["import os\n","import sys\n","import torch\n","os.chdir('/content/3d-lmnet-pytorch/3d-lmnet-pytorch')\n","sys.path.insert(1, \"/content/3d-lmnet-pytorch/3d-lmnet-pytorch\")\n","print('CUDA availability:', torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXCyGAKZtrLd"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","from pathlib import Path\n","import numpy as np\n","import matplotlib as plt\n","import k3d\n","import trimesh\n","import torch\n","import skimage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1673190666137,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"9mlePuTzttf0","outputId":"fecb3fd5-d0fc-459b-cf03-2ed270112f75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["torch.cuda.is_available()"]},{"cell_type":"markdown","metadata":{"id":"zUT-2sxV3ojS"},"source":["## ShapeNet Terms and Conditions\n","\n","In order to be able to use the data, we agree the below terms and conditions:\n","\n","1. Researcher shall use the Database only for non-commercial research and educational purposes.\n","2. Princeton University and Stanford University make no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose.\n","3. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify Princeton University and Stanford University, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted 3D models that he or she may create from the Database.\n","4. Researcher may provide research associates and colleagues with access to the Database provided that they first agree to be bound by these terms and conditions.\n","5. Princeton University and Stanford University reserve the right to terminate Researcher's access to the Database at any time.\n","6. If Researcher is employed by a for-profit, commercial entity, Researcher's employer shall also be bound by these terms and conditions, and Researcher hereby represents that he or she is fully authorized to enter into this agreement on behalf of such employer.\n","7. The law of the State of New Jersey shall apply to all disputes under this agreement."]},{"cell_type":"markdown","metadata":{"id":"aU6UFVmB2sDw"},"source":["### Unzip ShapeNet pointcloud zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHN_mJLtJYkz"},"outputs":[],"source":["!unzip -q ./data/ShapeNet_pointclouds.zip -d ./data"]},{"cell_type":"markdown","metadata":{"id":"gnY06WQ92yzn"},"source":["### Download 2D images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":869423,"status":"ok","timestamp":1673191576775,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"WGwtTRnW40w_","outputId":"65ed50fb-7180-4048-963c-68ba661be525"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-01-08 15:11:47--  http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Resolving cvgl.stanford.edu (cvgl.stanford.edu)... 171.64.64.64\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz [following]\n","--2023-01-08 15:11:47--  https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12318245442 (11G) [application/x-gzip]\n","Saving to: ‘./data/ShapeNetRendering.tgz’\n","\n","ShapeNetRendering.t 100%[===================>]  11.47G  13.7MB/s    in 14m 28s \n","\n","2023-01-08 15:26:15 (13.5 MB/s) - ‘./data/ShapeNetRendering.tgz’ saved [12318245442/12318245442]\n","\n"]}],"source":["!wget http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz -P ./data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdDWzJHLAcDz"},"outputs":[],"source":["!tar -xf ./data/ShapeNetRendering.tgz -C ./data\n","#!rm /content/term-project/data/ShapeNetRendering.tgz"]},{"cell_type":"markdown","metadata":{"id":"9WpwE3tS22bA"},"source":["### Construct ShapeNet dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1185,"status":"ok","timestamp":1673192047354,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"pKdGd1kvv7ub","outputId":"4f771e10-739e-4ecd-8203-7997fef687f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of train set: 26271\n","Length of val set: 8758\n","Length of test set: 8755\n"]}],"source":["from data.shapenet import ShapeNet\n","\n","# Create a dataset with train split\n","train_dataset = ShapeNet('train')\n","val_dataset = ShapeNet('valid')\n","#overfit_dataset = ShapeNet('overfit')\n","test_dataset = ShapeNet('test')\n","\n","# Get length, which is a call to __len__ function\n","print(f'Length of train set: {len(train_dataset)}') \n","# Get length, which is a call to __len__ function\n","print(f'Length of val set: {len(val_dataset)}') \n","# Get length, which is a call to __len__ function\n","print(f'Length of test set: {len(test_dataset)}')  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":825,"status":"ok","timestamp":1673192049606,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"-enEihrj4z-T","outputId":"f7bf3c16-a536-4e46-a519-4c8d10d3d6dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input images: (24, 137, 3, 137)\n","Input point cloud: (2048, 3)\n"]}],"source":["\n","from skimage.measure import marching_cubes\n","\n","train_sample = train_dataset[1]\n","print(f'Input images: {train_sample[\"img\"].shape}')  \n","print(f'Input point cloud: {train_sample[\"point\"].shape}')  "]},{"cell_type":"markdown","metadata":{"id":"_s5meRr62_S1"},"source":["### Print output shape of the 2D Encoder model (both variational and normal versions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":310,"status":"error","timestamp":1673042434619,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"W5zhCIIZlEui","outputId":"e86476d1-5b86-48c5-d950-9eeb2cf35405"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-0b9aacc72ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel2d_variational\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"variational\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m137\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m137\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/model/model_2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, final_layer, bottleneck)\u001b[0m\n\u001b[1;32m      8\u001b[0m         self.base = nn.Sequential(\n\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mpadding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mdilation_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         super(Conv2d, self).__init__(\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         padding, valid_padding_strings))\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'same'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"padding='same' is not supported for strided convolutions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mvalid_padding_modes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'circular'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: padding='same' is not supported for strided convolutions"]}],"source":["from model.model_2d import ImageEncoder\n","\n","model2d_variational=ImageEncoder(\"variational\",512)\n","\n","input_tensor = torch.randn(137,137,3)\n","mu,std = model2d_variational(input_tensor)\n","print(\"Mu:\",mu,\"Std:\",std)\n","\n","model2d_normal=ImageEncoder(\"normal\",512)\n","\n","latent=model2d_normal(input_tensor)\n","print(\"Latent shape:\",latent.shape)"]},{"cell_type":"markdown","metadata":{"id":"XhQwt86S3KLX"},"source":["### Train 2D Encoder model to match the predicted latent space to the output of 3D Encoder of pointclouds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"elapsed":526,"status":"error","timestamp":1673042443823,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"H5AfhbLEnbIt","outputId":"419ba570-6081-45c8-bde8-9fd321815170"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-5ed24ae0dd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel2d_variational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneralization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model2d_variational' is not defined"]}],"source":["from training import train_2d_to_3d\n","\n","generalization_config = {\n","    'experiment_name': '2d_to_3d_variational',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'is_overfit': False,\n","    'bottleneck': 512,\n","    'batch_size': 32,\n","    'resume_ckpt': None,\n","    'learning_rate_model':  0.00005,\n","    'max_epochs': 30,  \n","    'print_every_n': 5,\n","    'visualize_every_n': 5,\n","}\n","\n","model2d_variational.main(generalization_config)"]},{"cell_type":"markdown","metadata":{"id":"BMfuS_dL3T-A"},"source":["### Infer pointclouds using trained 2D Encoder and 3D Decoder models"]},{"cell_type":"markdown","metadata":{"id":"NFRpLXYm3ef-"},"source":["Variational inferences:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1KCfUPQoRIT"},"outputs":[],"source":["from inference.infer_2d_to_3d import Inference2DToPointCloudVariational\n","\n","device = torch.device('cuda:0')  # change this to cpu if you're not using a gpu\n","id=torch.randint(0,len(test_dataset))\n","val_config={\"final_layer\" : \"variational\",\n","        \"bottleneck\" : 512,\n","        \"input_size\" : None,\n","        \"hidden_size\" : None,\n","        \"output_size\" : None,\n","        \"bnorm\" : True,\n","        \"bnorm_final\" : False,\n","        \"regularizer\" : None,\n","        \"weight_decay\" : 0.001,\n","        \"dropout_prob\" : None}\n","Inference2DToPointCloudVariational(test_dataset[id],\"content/3d-lmnet-pytorch/runs/2d_to_3d_variational\",\"content/3d-lmnet-pytorch/runs/3d_pointcloud_decoder\", val_config,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6fnyhF1pPSo"},"outputs":[],"source":["predicted_point_clouds=inference_handler_variational.infer()"]},{"cell_type":"markdown","metadata":{"id":"xa-wqJSr3hk-"},"source":["Normal inferences:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRDWqdt1vZ5d"},"outputs":[],"source":["from inference.infer_2d_to_3d import Inference2DToPointCloudNormal\n","\n","id=torch.randint(0,len(test_dataset))\n","val_config={\"final_layer\" : \"normal\",\n","        \"bottleneck\" : 512,\n","        \"input_size\" : None,\n","        \"hidden_size\" : None,\n","        \"output_size\" : None,\n","        \"bnorm\" : True,\n","        \"bnorm_final\" : False,\n","        \"regularizer\" : None,\n","        \"weight_decay\" : 0.001,\n","        \"dropout_prob\" : None}\n","Inference2DToPointCloudNormal(test_dataset[id],\"content/3d-lmnet-pytorch/runs/2d_to_3d_normal\", \"content/3d-lmnet-pytorch/runs/3d_pointcloud_decoder\",val_config,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"77ic7G8_vm0f"},"outputs":[],"source":["predicted_point_cloud=inference_handler_normal.infer()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":1062,"status":"error","timestamp":1673193571117,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"3dU0c36AFxVJ","outputId":"b717d346-e9e8-428b-d2ce-83dd09ad51a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mBegin Training...\u001b[0m\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-b0671c3efd42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneralization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/training/train_ae.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mpoint_clouds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m#point_clouds = point_clouds.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mrecons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchamfer_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/model/model_3d_autoencoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/model/model_3d_autoencoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x512 and 256x256)"]}],"source":["from training import train_ae\n","\n","\n","    # parser.add_argument(\"--root\", type=str, default=\"./data\")\n","    # parser.add_argument(\"--npoints\", type=int, default=2048)\n","    # parser.add_argument(\"--mpoints\", type=int, default=2025)\n","    # parser.add_argument(\"--batch_size\", type=int, default=16)\n","    # parser.add_argument(\"--lr\", type=float, default=1e-4)\n","    # parser.add_argument(\"--weight_decay\", type=float, default=1e-6)\n","    # parser.add_argument(\"--epochs\", type=int, default=400)\n","    # parser.add_argument(\"--num_workers\", type=int, default=4)\n","    # parser.add_argument(\"--log_dir\", type=str, default=\"./log\")\n","\n","generalization_config = {\n","    'root': './3d-lmnet-pytorch/',\n","    'experiment_name': '3d_autoencoder',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'is_overfit': False,\n","    'npoints': 2048,\n","    'mpoints': 2025,\n","    'lr': 1e-4,\n","    'weight_decay': 1e-6,\n","    'bottleneck': 512,\n","    'batch_size': 16,\n","    'resume_ckpt': None,\n","    'learning_rate_model':  0.00005,\n","    'max_epochs': 400,  \n","    'num_workers': 4,\n","    \"input_size\" : 256,\n","    \"hidden_size\" : 256,\n","    \"output_size\" : 512,\n","    'log_dir': './3d-lmnet-pytorch/',\n","    'print_every_n': 5,\n","    'visualize_every_n': 5,\n","}\n","\n","train_ae.main(generalization_config)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"1a453b615765addad4971118d8a9ab96c4ea1423c3e71d4bd1e873af4a20b25f"}}},"nbformat":4,"nbformat_minor":0}