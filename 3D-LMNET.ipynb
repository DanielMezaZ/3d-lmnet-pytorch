{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNS1USs+nxqPXTetfubwbmA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# We assume you uploaded the exercise folder in root Google Drive folder\n","!cp -r /content/drive/MyDrive/term_project term_project\n","os.chdir('/content/drive/MyDrive/term_project')\n","print('Installing requirements')\n","!pip install -r requirements.txt\n","\n","# Make sure you restart runtime when directed by Colab"],"metadata":{"id":"2C8V1skstgvC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","os.chdir('/content/term_project')\n","sys.path.insert(1, \"/content/term_project\")\n","print('CUDA availability:', torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jmMRX90tj2P","executionInfo":{"status":"ok","timestamp":1671319814673,"user_tz":-60,"elapsed":2477,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"}},"outputId":"c8280295-5d81-4fff-9e05-936bb10c7366"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA availability: True\n"]}]},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","from pathlib import Path\n","import numpy as np\n","import matplotlib as plt\n","import k3d\n","import trimesh\n","import torch\n","import skimage"],"metadata":{"id":"eXCyGAKZtrLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mlePuTzttf0","executionInfo":{"status":"ok","timestamp":1671319821497,"user_tz":-60,"elapsed":4,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"}},"outputId":"bdb76141-83be-4b10-f783-9478cd92ffc1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## ShapeNet Terms and Conditions\n","\n","In order to be able to use the data, we agree the below terms and conditions:\n","\n","1. Researcher shall use the Database only for non-commercial research and educational purposes.\n","2. Princeton University and Stanford University make no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose.\n","3. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify Princeton University and Stanford University, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted 3D models that he or she may create from the Database.\n","4. Researcher may provide research associates and colleagues with access to the Database provided that they first agree to be bound by these terms and conditions.\n","5. Princeton University and Stanford University reserve the right to terminate Researcher's access to the Database at any time.\n","6. If Researcher is employed by a for-profit, commercial entity, Researcher's employer shall also be bound by these terms and conditions, and Researcher hereby represents that he or she is fully authorized to enter into this agreement on behalf of such employer.\n","7. The law of the State of New Jersey shall apply to all disputes under this agreement."],"metadata":{"id":"zUT-2sxV3ojS"}},{"cell_type":"markdown","source":["### Unzip ShapeNet pointcloud zip"],"metadata":{"id":"aU6UFVmB2sDw"}},{"cell_type":"code","source":["!unzip -q /content/term_project/data/ShapeNet_pointclouds.zip -d /content/term_project/data"],"metadata":{"id":"yHN_mJLtJYkz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Download 2D images"],"metadata":{"id":"gnY06WQ92yzn"}},{"cell_type":"code","source":["!wget http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz -P /content/term_project/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGwtTRnW40w_","executionInfo":{"status":"ok","timestamp":1671320664113,"user_tz":-60,"elapsed":789300,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"}},"outputId":"27f148a6-f807-42ad-da5c-8e4cfed5173b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-17 23:31:14--  http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Resolving cvgl.stanford.edu (cvgl.stanford.edu)... 171.64.64.64\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz [following]\n","--2022-12-17 23:31:14--  https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12318245442 (11G) [application/x-gzip]\n","Saving to: ‘/content/term_project/data/ShapeNetRendering.tgz’\n","\n","ShapeNetRendering.t 100%[===================>]  11.47G  13.1MB/s    in 13m 8s  \n","\n","2022-12-17 23:44:23 (14.9 MB/s) - ‘/content/term_project/data/ShapeNetRendering.tgz’ saved [12318245442/12318245442]\n","\n"]}]},{"cell_type":"code","source":["!tar -xf /content/term_project/data/ShapeNetRendering.tgz -C /content/term_project/data\n","#!rm /content/term-project/data/ShapeNetRendering.tgz"],"metadata":{"id":"BdDWzJHLAcDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Construct ShapeNet dataset"],"metadata":{"id":"9WpwE3tS22bA"}},{"cell_type":"code","source":["from term_project.data.shapenet import ShapeNet\n","\n","# Create a dataset with train split\n","train_dataset = ShapeNet('train')\n","val_dataset = ShapeNet('valid')\n","#overfit_dataset = ShapeNet('overfit')\n","test_dataset = ShapeNet('test')\n","\n","# Get length, which is a call to __len__ function\n","print(f'Length of train set: {len(train_dataset)}') \n","# Get length, which is a call to __len__ function\n","print(f'Length of val set: {len(val_dataset)}') \n","# Get length, which is a call to __len__ function\n","print(f'Length of test set: {len(test_dataset)}')  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pKdGd1kvv7ub","executionInfo":{"status":"ok","timestamp":1671322632567,"user_tz":-60,"elapsed":5,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"}},"outputId":"fc55a18d-6658-4525-9eb9-c142aa2d8090"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of train set: 4067\n","Length of val set: 1356\n","Length of overfit set: 1355\n"]}]},{"cell_type":"code","source":["\n","from skimage.measure import marching_cubes\n","\n","train_sample = train_dataset[1]\n","print(f'Input images: {train_sample[\"img\"].shape}')  \n","print(f'Input point cloud: {train_sample[\"point\"].shape}')  "],"metadata":{"id":"-enEihrj4z-T","executionInfo":{"status":"ok","timestamp":1671322237298,"user_tz":-60,"elapsed":931,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec44fd6c-0f72-409d-e8f8-8db1df24e8ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input images: (24, 137, 137, 3)\n","Input point cloud: (2048, 3)\n"]}]},{"cell_type":"markdown","source":["### Print output shape of the 2D Encoder model (both variational and normal versions)"],"metadata":{"id":"_s5meRr62_S1"}},{"cell_type":"code","source":["from term_project.model.model_2d import TwoDeeEncoder\n","\n","model2d_variational=TwoDeeEncoder(\"variational\",512)\n","\n","input_tensor = torch.randn(137,137,3)\n","mu,std = model2_variational(input_tensor)\n","print(\"Mu:\",mu,\"Std:\",std)\n","\n","model2d_normal=TwoDeeEncoder(\"normal\",512)\n","\n","latent=model2d_normal(input_tensor)\n","print(\"Latent shape:\",latent.shape)"],"metadata":{"id":"W5zhCIIZlEui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Train 2D Encoder model to match the predicted latent space to the output of 3D Encoder of pointclouds"],"metadata":{"id":"XhQwt86S3KLX"}},{"cell_type":"code","source":["from term_project.training import train_2d_to_pointcloud_matching\n","\n","generalization_config = {\n","    'experiment_name': '2d_image_to_pointclud_matching_variational',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'is_overfit': False,\n","    'bottleneck': 512,\n","    'batch_size': 32,\n","    'resume_ckpt': None,\n","    'learning_rate_model':  0.00005,\n","    'max_epochs': 30,  \n","    'print_every_n': 5,\n","    'visualize_every_n': 5,\n","}\n","\n","model2d_variational.main(generalization_config)"],"metadata":{"id":"H5AfhbLEnbIt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Infer pointclouds using trained 2D Encoder and 3D Decoder models"],"metadata":{"id":"BMfuS_dL3T-A"}},{"cell_type":"markdown","source":["Variational inferences:"],"metadata":{"id":"NFRpLXYm3ef-"}},{"cell_type":"code","source":["from term_project.inference.infer_2d_to_pointcloud import Inference2DToPointcloudVariational\n","\n","device = torch.device('cuda:0')  # change this to cpu if you're not using a gpu\n","id=torch.randint(0,len(test_dataset))\n","val_config={\"final_layer\":\"variational\",\"bottleneck\":512,\"input_size\":None,\n","        \"hidden_size\":None,\n","        \"output_size\":None,\n","        \"bnorm\"=True,\n","        \"bnorm_final\"=False,\n","        \"regularizer\"=None,\n","        \"weight_decay\"=0.001,\n","        \"dropout_prob\"=None}\n","Inference2DToPointcloudVariational( test_dataset[id],\"term_project/runs/2d_image_to_pointclud_matching_variational\",\"term_project/runs/3d_pointcloud_decoder\", val_config,device)"],"metadata":{"id":"l1KCfUPQoRIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_point_clouds=inference_handler_variational.infer()"],"metadata":{"id":"w6fnyhF1pPSo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Normal inferences:"],"metadata":{"id":"xa-wqJSr3hk-"}},{"cell_type":"code","source":["from term_project.inference.infer_2d_to_pointcloud import Inference2DToPointcloudNormal\n","id=torch.randint(0,len(test_dataset))\n","val_config={\"final_layer\":\"normal\",\"bottleneck\":512,\"input_size\":None,\n","        \"hidden_size\":None,\n","        \"output_size\":None,\n","        \"bnorm\"=True,\n","        \"bnorm_final\"=False,\n","        \"regularizer\"=None,\n","        \"weight_decay\"=0.001,\n","        \"dropout_prob\"=None}\n","Inference2DToPointcloudNormal(test_dataset[id],\"term_project/runs/2d_image_to_pointclud_matching_normal\", \"term_project/runs/3d_pointcloud_decoder\",val_config,device)"],"metadata":{"id":"qRDWqdt1vZ5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_point_cloud=inference_handler_normal.infer()"],"metadata":{"id":"77ic7G8_vm0f"},"execution_count":null,"outputs":[]}]}