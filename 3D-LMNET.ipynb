{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2C8V1skstgvC","outputId":"99108b80-83c1-4613-e9d8-d02f261864d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# We assume you uploaded the exercise folder in root Google Drive folder\n","!cp -r /content/drive/MyDrive/3d-lmnet-pytorch 3d-lmnet-pytorch\n","os.chdir('/content/drive/MyDrive/3d-lmnet-pytorch')\n","print('Installing requirements')\n","!pip install -r requirements.txt\n","\n","# Make sure you restart runtime when directed by Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3656,"status":"ok","timestamp":1673266352508,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"9jmMRX90tj2P","outputId":"4b85219f-1c5f-4a14-b931-9e21f5ff11a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA availability: True\n"]}],"source":["import os\n","import sys\n","import torch\n","os.chdir('/content/3d-lmnet-pytorch/3d-lmnet-pytorch')\n","sys.path.insert(1, \"/content/3d-lmnet-pytorch/3d-lmnet-pytorch\")\n","print('CUDA availability:', torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXCyGAKZtrLd"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","from pathlib import Path\n","import numpy as np\n","import matplotlib as plt\n","import k3d\n","import trimesh\n","import torch\n","import skimage"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1673266483751,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"9mlePuTzttf0","outputId":"01bf416f-f383-439c-8b14-54b4c615948c"},"outputs":[{"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available()\n","\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["torch.cuda.is_available()\n","need_pytorch3d=False\n","try:\n","    import pytorch3d\n","except ModuleNotFoundError:\n","    need_pytorch3d=True\n","if need_pytorch3d:\n","    if sys.platform.startswith(\"linux\"):\n","        # We try to install PyTorch3D via a released wheel.\n","        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n","        version_str=\"\".join([\n","            f\"py3{sys.version_info.minor}_cu\",\n","            torch.version.cuda.replace(\".\",\"\"),\n","            f\"_pyt{pyt_version_str}\"\n","        ])\n","        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n","    else:\n","        # We try to install PyTorch3D from source.\n","        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n","        !tar xzf 1.10.0.tar.gz\n","        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n","        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"]},{"cell_type":"markdown","metadata":{"id":"zUT-2sxV3ojS"},"source":["## ShapeNet Terms and Conditions\n","\n","In order to be able to use the data, we agree the below terms and conditions:\n","\n","1. Researcher shall use the Database only for non-commercial research and educational purposes.\n","2. Princeton University and Stanford University make no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose.\n","3. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify Princeton University and Stanford University, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted 3D models that he or she may create from the Database.\n","4. Researcher may provide research associates and colleagues with access to the Database provided that they first agree to be bound by these terms and conditions.\n","5. Princeton University and Stanford University reserve the right to terminate Researcher's access to the Database at any time.\n","6. If Researcher is employed by a for-profit, commercial entity, Researcher's employer shall also be bound by these terms and conditions, and Researcher hereby represents that he or she is fully authorized to enter into this agreement on behalf of such employer.\n","7. The law of the State of New Jersey shall apply to all disputes under this agreement."]},{"cell_type":"markdown","metadata":{"id":"aU6UFVmB2sDw"},"source":["### Unzip ShapeNet pointcloud zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yHN_mJLtJYkz"},"outputs":[],"source":["!unzip -q ./data/ShapeNet_pointclouds.zip -d ./data"]},{"cell_type":"markdown","metadata":{"id":"gnY06WQ92yzn"},"source":["### Download 2D images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":893845,"status":"ok","timestamp":1673267431815,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"WGwtTRnW40w_","outputId":"d3508c4c-ebde-49dc-86fe-b6dca3af9970"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-01-09 12:15:37--  http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Resolving cvgl.stanford.edu (cvgl.stanford.edu)... 171.64.64.64\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz [following]\n","--2023-01-09 12:15:38--  https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n","Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12318245442 (11G) [application/x-gzip]\n","Saving to: ‘./data/ShapeNetRendering.tgz’\n","\n","ShapeNetRendering.t 100%[===================>]  11.47G  14.1MB/s    in 14m 52s \n","\n","2023-01-09 12:30:31 (13.2 MB/s) - ‘./data/ShapeNetRendering.tgz’ saved [12318245442/12318245442]\n","\n"]}],"source":["!wget http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz -P ./data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdDWzJHLAcDz"},"outputs":[],"source":["!tar -xf ./data/ShapeNetRendering.tgz -C ./data\n","#!rm /content/term-project/data/ShapeNetRendering.tgz"]},{"cell_type":"markdown","metadata":{"id":"9WpwE3tS22bA"},"source":["### Construct ShapeNet dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":963,"status":"ok","timestamp":1673267609006,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"pKdGd1kvv7ub","outputId":"8b9c7351-e838-482e-8926-8df9084e976c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of train set: 26271\n","Length of val set: 8758\n","Length of test set: 8755\n"]}],"source":["from data.shapenet import ShapeNet\n","\n","# Create a dataset with train split\n","train_dataset = ShapeNet('train')\n","val_dataset = ShapeNet('valid')\n","#overfit_dataset = ShapeNet('overfit')\n","test_dataset = ShapeNet('test')\n","\n","# Get length, which is a call to __len__ function\n","print(f'Length of train set: {len(train_dataset)}') \n","# Get length, which is a call to __len__ function\n","print(f'Length of val set: {len(val_dataset)}') \n","# Get length, which is a call to __len__ function\n","print(f'Length of test set: {len(test_dataset)}')  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1239,"status":"ok","timestamp":1673267612740,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"-enEihrj4z-T","outputId":"5b468419-f33c-461b-9e7f-6d34913dae5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input images: (24, 137, 3, 137)\n","Input point cloud: (2048, 3)\n"]}],"source":["\n","from skimage.measure import marching_cubes\n","\n","train_sample = train_dataset[1]\n","print(f'Input images: {train_sample[\"img\"].shape}')  \n","print(f'Input point cloud: {train_sample[\"point\"].shape}')  "]},{"cell_type":"markdown","metadata":{"id":"_s5meRr62_S1"},"source":["### Print output shape of the 2D Encoder model (both variational and normal versions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"elapsed":310,"status":"error","timestamp":1673042434619,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"W5zhCIIZlEui","outputId":"e86476d1-5b86-48c5-d950-9eeb2cf35405"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-0b9aacc72ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel2d_variational\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"variational\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m137\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m137\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/model/model_2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, final_layer, bottleneck)\u001b[0m\n\u001b[1;32m      8\u001b[0m         self.base = nn.Sequential(\n\u001b[1;32m      9\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mpadding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mdilation_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         super(Conv2d, self).__init__(\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             False, _pair(0), groups, bias, padding_mode, **factory_kwargs)\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                         padding, valid_padding_strings))\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'same'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"padding='same' is not supported for strided convolutions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mvalid_padding_modes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'circular'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: padding='same' is not supported for strided convolutions"]}],"source":["from model.model_2d import ImageEncoder\n","\n","model2d_variational=ImageEncoder(\"variational\",512)\n","\n","input_tensor = torch.randn(137,137,3)\n","mu,std = model2d_variational(input_tensor)\n","print(\"Mu:\",mu,\"Std:\",std)\n","\n","model2d_normal=ImageEncoder(\"normal\",512)\n","\n","latent=model2d_normal(input_tensor)\n","print(\"Latent shape:\",latent.shape)"]},{"cell_type":"markdown","metadata":{"id":"XhQwt86S3KLX"},"source":["### Train 2D Encoder model to match the predicted latent space to the output of 3D Encoder of pointclouds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"elapsed":526,"status":"error","timestamp":1673042443823,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"H5AfhbLEnbIt","outputId":"419ba570-6081-45c8-bde8-9fd321815170"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-5ed24ae0dd07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel2d_variational\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneralization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model2d_variational' is not defined"]}],"source":["from training import train_2d_to_3d\n","\n","generalization_config = {\n","    'experiment_name': '2d_to_3d_variational',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'is_overfit': False,\n","    'bottleneck': 512,\n","    'batch_size': 32,\n","    'resume_ckpt': None,\n","    'learning_rate_model':  0.00005,\n","    'max_epochs': 30,  \n","    'print_every_n': 5,\n","    'visualize_every_n': 5,\n","}\n","\n","model2d_variational.main(generalization_config)"]},{"cell_type":"markdown","metadata":{"id":"BMfuS_dL3T-A"},"source":["### Infer pointclouds using trained 2D Encoder and 3D Decoder models"]},{"cell_type":"markdown","metadata":{"id":"NFRpLXYm3ef-"},"source":["Variational inferences:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1KCfUPQoRIT"},"outputs":[],"source":["from inference.infer_2d_to_3d import Inference2DToPointCloudVariational\n","\n","device = torch.device('cuda:0')  # change this to cpu if you're not using a gpu\n","id=torch.randint(0,len(test_dataset))\n","val_config={\"final_layer\" : \"variational\",\n","        \"bottleneck\" : 512,\n","        \"input_size\" : None,\n","        \"hidden_size\" : None,\n","        \"output_size\" : None,\n","        \"bnorm\" : True,\n","        \"bnorm_final\" : False,\n","        \"regularizer\" : None,\n","        \"weight_decay\" : 0.001,\n","        \"dropout_prob\" : None}\n","Inference2DToPointCloudVariational(test_dataset[id],\"content/3d-lmnet-pytorch/runs/2d_to_3d_variational\",\"content/3d-lmnet-pytorch/runs/3d_pointcloud_decoder\", val_config,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6fnyhF1pPSo"},"outputs":[],"source":["predicted_point_clouds=inference_handler_variational.infer()"]},{"cell_type":"markdown","metadata":{"id":"xa-wqJSr3hk-"},"source":["Normal inferences:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRDWqdt1vZ5d"},"outputs":[],"source":["from inference.infer_2d_to_3d import Inference2DToPointCloudNormal\n","\n","id=torch.randint(0,len(test_dataset))\n","val_config={\"final_layer\" : \"normal\",\n","        \"bottleneck\" : 512,\n","        \"input_size\" : None,\n","        \"hidden_size\" : None,\n","        \"output_size\" : None,\n","        \"bnorm\" : True,\n","        \"bnorm_final\" : False,\n","        \"regularizer\" : None,\n","        \"weight_decay\" : 0.001,\n","        \"dropout_prob\" : None}\n","Inference2DToPointCloudNormal(test_dataset[id],\"content/3d-lmnet-pytorch/runs/2d_to_3d_normal\", \"content/3d-lmnet-pytorch/runs/3d_pointcloud_decoder\",val_config,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"elapsed":1600,"status":"error","timestamp":1673274031390,"user":{"displayName":"ml3d dai","userId":"13876971419975352583"},"user_tz":-60},"id":"3dU0c36AFxVJ","outputId":"9ca6193c-3a21-400e-ed94-f4d76aa0ef5f"},"outputs":[{"name":"stdout","output_type":"stream","text":[" initial input 512 initial hidden 16 initial output 3\n","\u001b[31mBegin Training...\u001b[0m\n","initial point cloud size torch.Size([16, 3, 2048])\n","tensor size after encoder torch.Size([16, 512])\n","tensor size after decoder torch.Size([16, 3])\n","recons size torch.Size([16, 3, 1])\n","point cloud size before loss function torch.Size([16, 2048, 3])\n","recons size before loss function torch.Size([16, 1, 3])\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-50-55adbbeb75b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneralization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/training/train_ae.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recons size before loss function \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchamfer_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m            \u001b[0;31m# optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/utils/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdists_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdists_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["from training import train_ae\n","\n","\n","    # parser.add_argument(\"--root\", type=str, default=\"./data\")\n","    # parser.add_argument(\"--npoints\", type=int, default=2048)\n","    # parser.add_argument(\"--mpoints\", type=int, default=2025)\n","    # parser.add_argument(\"--batch_size\", type=int, default=16)\n","    # parser.add_argument(\"--lr\", type=float, default=1e-4)\n","    # parser.add_argument(\"--weight_decay\", type=float, default=1e-6)\n","    # parser.add_argument(\"--epochs\", type=int, default=400)\n","    # parser.add_argument(\"--num_workers\", type=int, default=4)\n","    # parser.add_argument(\"--log_dir\", type=str, default=\"./log\")\n","\n","generalization_config = {\n","    'root': './3d-lmnet-pytorch/',\n","    'experiment_name': '3d_autoencoder',\n","    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n","    'is_overfit': False,\n","    'npoints': 2048,\n","    'mpoints': 2025,\n","    'lr': 1e-4,\n","    \"autoencoder\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches/model_epoch_300.pth\",\n","    'weight_decay': 1e-6,\n","    'bottleneck': 512,\n","    'batch_size': 32,\n","    'resume_ckpt': None,\n","    'learning_rate_model':  0.00005,\n","    'max_epochs': 200,  \n","    'num_workers': 4,\n","    \"input_size\" : 256,\n","    \"hidden_size\" : 256,\n","    \"output_size\" : 2048*3,\n","    'log_dir': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches',\n","    'print_every_n': 5,\n","    'visualize_every_n': 5,\n","}\n","\n","train_ae.main(generalization_config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoaKVSVfgnMc"},"outputs":[],"source":["from inference import infer_3d\n","\n","generalization_config = {\n","    \"autoencoder\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n","    'bottleneck': 512,\n","    'batch_size': 1,\n","    'num_workers': 4,\n","    \"input_size\" : 256,\n","    \"hidden_size\" : 256,\n","    \"output_size\" : 2048*3,\n","}\n","\n","infer_3d.main(generalization_config)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"1a453b615765addad4971118d8a9ab96c4ea1423c3e71d4bd1e873af4a20b25f"}}},"nbformat":4,"nbformat_minor":0}
