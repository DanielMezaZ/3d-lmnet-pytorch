{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2C8V1skstgvC",
        "outputId": "1988c41c-c37a-4745-fabb-eee33c3a84b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Installing requirements\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jupyter>=1.0.0\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting K3D>=2.9.4\n",
            "  Downloading k3d-2.15.2-py3-none-any.whl (23.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.0/23.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=3.4.1\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh>=3.9.14\n",
            "  Downloading trimesh-3.18.1-py3-none-any.whl (670 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.9/670.9 KB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.13.1+cu116)\n",
            "Collecting pytorch-lightning>=1.2.8\n",
            "  Downloading pytorch_lightning-1.9.0-py3-none-any.whl (825 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 KB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (0.18.3)\n",
            "Collecting pyrender>=0.1.43\n",
            "  Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting moviepy>=1.0.3\n",
            "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 KB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pillow>=7.2.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (4.64.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.19.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (1.21.6)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (5.3.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (7.7.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (6.1.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter>=1.0.0->-r requirements.txt (line 1)) (5.7.16)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: traitlets in /usr/local/lib/python3.8/dist-packages (from K3D>=2.9.4->-r requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from K3D>=2.9.4->-r requirements.txt (line 2)) (1.0.4)\n",
            "Collecting traittypes\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.4.1->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.1->-r requirements.txt (line 5)) (4.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (6.0)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 KB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (2022.11.0)\n",
            "Collecting lightning-utilities>=0.4.2\n",
            "  Downloading lightning_utilities-0.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (3.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.18.1->-r requirements.txt (line 7)) (2022.10.10)\n",
            "Collecting pyglet>=1.4.10\n",
            "  Downloading pyglet-2.0.3-py3-none-any.whl (968 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m968.6/968.6 KB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pyrender>=0.1.43->-r requirements.txt (line 8)) (1.15.0)\n",
            "Collecting PyOpenGL==3.1.0\n",
            "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting freetype-py\n",
            "  Downloading freetype_py-2.3.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (978 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.9/978.9 KB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 9)) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 9)) (2.25.1)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Collecting imageio_ffmpeg>=0.2.0\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (3.8.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.0.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (7.9.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter>=1.0.0->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.6.1)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.6.0)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.11.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.1.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.13.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.15.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (1.8.0)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.2.8->-r requirements.txt (line 6)) (4.0.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2>=2.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.6.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (4.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.8.3)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (5.10.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (0.19.3)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.4->nbconvert->jupyter>=1.0.0->-r requirements.txt (line 1)) (3.11.0)\n",
            "Building wheels for collected packages: PyOpenGL, moviepy\n",
            "  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1745210 sha256=1d29d19ecdaed7dacb87c08b44df3f29f72eac29bf8cacc5ae6f8729ae7b76e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/ff/54/41f30bb227befd3dde302de39f9ba042589e8b4f93723107f2\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110742 sha256=692bce6cc9c207b5e3cadf2b09f213622e0f128388c41fd7fc496ed31d102a24\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/a4/db/0368d3a04033da662e13926594b3a8cf1aa4ffeefe570cfac1\n",
            "Successfully built PyOpenGL moviepy\n",
            "Installing collected packages: PyOpenGL, pyglet, trimesh, traittypes, proglog, pillow, jedi, imageio_ffmpeg, freetype-py, fonttools, contourpy, torchmetrics, qtpy, matplotlib, lightning-utilities, pyrender, moviepy, qtconsole, pytorch-lightning, K3D, jupyter\n",
            "  Attempting uninstall: PyOpenGL\n",
            "    Found existing installation: PyOpenGL 3.1.6\n",
            "    Uninstalling PyOpenGL-3.1.6:\n",
            "      Successfully uninstalled PyOpenGL-3.1.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: moviepy\n",
            "    Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "Successfully installed K3D-2.15.2 PyOpenGL-3.1.0 contourpy-1.0.7 fonttools-4.38.0 freetype-py-2.3.0 imageio_ffmpeg-0.4.8 jedi-0.18.2 jupyter-1.0.0 lightning-utilities-0.5.0 matplotlib-3.6.3 moviepy-1.0.3 pillow-9.4.0 proglog-0.1.10 pyglet-2.0.3 pyrender-0.1.45 pytorch-lightning-1.9.0 qtconsole-5.4.0 qtpy-2.3.0 torchmetrics-0.11.0 traittypes-0.2.1 trimesh-3.18.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# We assume you uploaded the exercise folder in root Google Drive folder\n",
        "!cp -r /content/drive/MyDrive/3d-lmnet-pytorch 3d-lmnet-pytorch\n",
        "os.chdir('/content/drive/MyDrive/3d-lmnet-pytorch')\n",
        "print('Installing requirements')\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Make sure you restart runtime when directed by Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jmMRX90tj2P",
        "outputId": "49359dd9-ba17-4ce5-db77-7f40591b7ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA availability: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "os.chdir('/content/3d-lmnet-pytorch/3d-lmnet-pytorch')\n",
        "sys.path.insert(1, \"/content/3d-lmnet-pytorch/3d-lmnet-pytorch\")\n",
        "print('CUDA availability:', torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eXCyGAKZtrLd"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import k3d\n",
        "import trimesh\n",
        "import torch\n",
        "import skimage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9mlePuTzttf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73752b58-41d5-4352-d43e-b2a6bebad728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py38_cu116_pyt1131/pytorch3d-0.7.2-cp38-cp38-linux_x86_64.whl (72.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.8/72.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (2.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorch3d) (4.4.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=dae88102cb2f454fff61746aa16f92e58e8ccdc1de939b044015ddbd05967f9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=944e590e6d0ea021809791109c2f48ea3b2dcc42bfa766583f8c9088b5ecb5c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore, pytorch3d\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.7.0 pytorch3d-0.7.2 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.is_available()\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUT-2sxV3ojS"
      },
      "source": [
        "## ShapeNet Terms and Conditions\n",
        "\n",
        "In order to be able to use the data, we agree the below terms and conditions:\n",
        "\n",
        "1. Researcher shall use the Database only for non-commercial research and educational purposes.\n",
        "2. Princeton University and Stanford University make no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose.\n",
        "3. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify Princeton University and Stanford University, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted 3D models that he or she may create from the Database.\n",
        "4. Researcher may provide research associates and colleagues with access to the Database provided that they first agree to be bound by these terms and conditions.\n",
        "5. Princeton University and Stanford University reserve the right to terminate Researcher's access to the Database at any time.\n",
        "6. If Researcher is employed by a for-profit, commercial entity, Researcher's employer shall also be bound by these terms and conditions, and Researcher hereby represents that he or she is fully authorized to enter into this agreement on behalf of such employer.\n",
        "7. The law of the State of New Jersey shall apply to all disputes under this agreement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU6UFVmB2sDw"
      },
      "source": [
        "### Unzip ShapeNet pointcloud zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yHN_mJLtJYkz"
      },
      "outputs": [],
      "source": [
        "!unzip -q ./data/ShapeNet_pointclouds.zip -d ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnY06WQ92yzn"
      },
      "source": [
        "### Download 2D images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGwtTRnW40w_",
        "outputId": "30d8cc83-a20c-40c4-b6fe-c8d2980f23a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-19 13:16:26--  http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n",
            "Resolving cvgl.stanford.edu (cvgl.stanford.edu)... 171.64.64.64\n",
            "Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz [following]\n",
            "--2023-01-19 13:16:26--  https://cvgl.stanford.edu/data2/ShapeNetRendering.tgz\n",
            "Connecting to cvgl.stanford.edu (cvgl.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12318245442 (11G) [application/x-gzip]\n",
            "Saving to: ‘./data/ShapeNetRendering.tgz’\n",
            "\n",
            "ShapeNetRendering.t   0%[                    ]   9.40M  6.96MB/s               "
          ]
        }
      ],
      "source": [
        "!wget http://cvgl.stanford.edu/data2/ShapeNetRendering.tgz -P ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdDWzJHLAcDz"
      },
      "outputs": [],
      "source": [
        "!tar -xf ./data/ShapeNetRendering.tgz -C ./data\n",
        "#!rm /content/term-project/data/ShapeNetRendering.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WpwE3tS22bA"
      },
      "source": [
        "### Construct ShapeNet dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKdGd1kvv7ub"
      },
      "outputs": [],
      "source": [
        "from data.shapenet import ShapeNet\n",
        "\n",
        "# Create a dataset with train split\n",
        "train_dataset = ShapeNet('train')\n",
        "val_dataset = ShapeNet('valid')\n",
        "#overfit_dataset = ShapeNet('overfit')\n",
        "test_dataset = ShapeNet('test')\n",
        "\n",
        "# Get length, which is a call to __len__ function\n",
        "print(f'Length of train set: {len(train_dataset)}') \n",
        "# Get length, which is a call to __len__ function\n",
        "print(f'Length of val set: {len(val_dataset)}') \n",
        "# Get length, which is a call to __len__ function\n",
        "print(f'Length of test set: {len(test_dataset)}')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-enEihrj4z-T"
      },
      "outputs": [],
      "source": [
        "\n",
        "from skimage.measure import marching_cubes\n",
        "\n",
        "train_sample = train_dataset[1]\n",
        "print(f'Input images: {train_sample[\"img\"].shape}')  \n",
        "print(f'Input point cloud: {train_sample[\"point\"].shape}')  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s5meRr62_S1"
      },
      "source": [
        "### Print output shape of the 2D Encoder model (both variational and normal versions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5zhCIIZlEui"
      },
      "outputs": [],
      "source": [
        "from model.model_2d import ImageEncoder\n",
        "from torchsummary import summary\n",
        "\n",
        "model2d_variational=ImageEncoder(\"variational\",128)\n",
        "model2d_variational.cuda()\n",
        "input_tensor = torch.randn(1,3,128,128)\n",
        "input_tensor=input_tensor.cuda()\n",
        "print(\"input size:\",input_tensor.size())\n",
        "\n",
        "\n",
        "mu,std = model2d_variational(input_tensor)\n",
        "print(\"Mu size:\",mu.size(),\"Std size:\",std.size())\n",
        "summary(model2d_variational,(3,128,128))\n",
        "model2d_normal=ImageEncoder(\"normal\",128)\n",
        "model2d_normal.cuda()\n",
        "latent=model2d_normal(input_tensor)\n",
        "print(\"Latent shape:\",latent.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQwt86S3KLX"
      },
      "source": [
        "### Train 2D Encoder model to match the predicted latent space to the output of 3D Encoder of pointclouds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal, L1 loss"
      ],
      "metadata": {
        "id": "uvuWag580_fw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5AfhbLEnbIt"
      },
      "outputs": [],
      "source": [
        "from training import train_2d_to_3d\n",
        "\n",
        "generalization_config = {\n",
        "    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L1',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'bottleneck': 512,\n",
        "    \"cat\":13,\n",
        "    'batch_size': 32,\n",
        "    \"loss_criterion\":\"L1\",\n",
        "    \"final_layer\":\"normal\",\n",
        "    \"3d_encoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    'max_epochs': 30,  \n",
        "    'save_every_n': 1,\n",
        "    'validate_every_n': 3,\n",
        "    \"autoencoder_bottleneck\":512,\n",
        "    \"autoencoder_hidden_size\":256,\n",
        "    \"autoencoder_output_size\":2048*3,\n",
        "    \"alpha\":None,\n",
        "    \"penalty_angle\":None,\n",
        "    \"lambda\":None\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "train_2d_to_3d.main(generalization_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal, L2 loss"
      ],
      "metadata": {
        "id": "0UT6VzUJ1TKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from training import train_2d_to_3d\n",
        "\n",
        "generalization_config = {\n",
        "    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L2',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'bottleneck': 512,\n",
        "    \"cat\":13,\n",
        "    'batch_size': 32,\n",
        "    \"loss_criterion\":\"L2\",\n",
        "    \"final_layer\":\"normal\",\n",
        "    \"3d_encoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    'max_epochs': 30,  \n",
        "    'save_every_n': 1,\n",
        "    'validate_every_n': 5,\n",
        "    \"autoencoder_bottleneck\":512,\n",
        "    \"autoencoder_hidden_size\":256,\n",
        "    \"autoencoder_output_size\":2048*3,\n",
        "    \"alpha\":None,\n",
        "    \"penalty_angle\":None,\n",
        "    \"lambda\":None\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "train_2d_to_3d.main(generalization_config)"
      ],
      "metadata": {
        "id": "fHNSisYe1VFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variational"
      ],
      "metadata": {
        "id": "cVjsNa1N1px7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from training import train_2d_to_3d\n",
        "\n",
        "generalization_config = {\n",
        "    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/variational',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'bottleneck': 512,\n",
        "    \"cat\":13,\n",
        "    'batch_size': 32,\n",
        "    \"loss_criterion\":\"variational\",\n",
        "    \"final_layer\":\"variational\",\n",
        "    \"3d_encoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    'max_epochs': 30,  \n",
        "    'save_every_n': 1,\n",
        "    'validate_every_n': 3,\n",
        "    \"autoencoder_bottleneck\":512,\n",
        "    \"autoencoder_hidden_size\":256,\n",
        "    \"autoencoder_output_size\":2048*3,\n",
        "    \"alpha\":0.2,\n",
        "    \"penalty_angle\":20,\n",
        "    \"lambda\":5.5\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "train_2d_to_3d.main(generalization_config)"
      ],
      "metadata": {
        "id": "xv-oEiXO1r0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMfuS_dL3T-A"
      },
      "source": [
        "### Infer pointclouds using trained 2D Encoder and 3D Decoder models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFRpLXYm3ef-"
      },
      "source": [
        "Variational inferences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1KCfUPQoRIT"
      },
      "outputs": [],
      "source": [
        "from inference import inference_2d_to_3d \n",
        "\n",
        "generalization_config = {\n",
        "    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/variational',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'bottleneck': 512,\n",
        "    \"cat\":13,\n",
        "    'batch_size': 32,\n",
        "    \"loss_criterion\":\"variational\",\n",
        "    \"final_layer\":\"variational\",\n",
        "    \"3d_encoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches/model_epoch_500.pth\",\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    \"autoencoder_bottleneck\":512,\n",
        "    \"autoencoder_hidden_size\":256,\n",
        "    \"autoencoder_output_size\":2048*3\n",
        "\n",
        "}\n",
        "inference_2d_to_3d.main(generalization_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-wqJSr3hk-"
      },
      "source": [
        "Normal inferences:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using L1 in the training"
      ],
      "metadata": {
        "id": "G4iWoRro2RBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRDWqdt1vZ5d"
      },
      "outputs": [],
      "source": [
        "from inference import inference_2d_to_3d \n",
        "\n",
        "generalization_config = {\n",
        "    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L1',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'bottleneck': 512,\n",
        "    \"cat\":13,\n",
        "    'batch_size': 32,\n",
        "    \"loss_criterion\":\"L1\",\n",
        "    \"final_layer\":\"normal\",\n",
        "    \"3d_encoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches/model_epoch_500.pth\",\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    \"autoencoder_bottleneck\":512,\n",
        "    \"autoencoder_hidden_size\":256,\n",
        "    \"autoencoder_output_size\":2048*3\n",
        "\n",
        "}\n",
        "inference_2d_to_3d.main(generalization_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using L2 in the training"
      ],
      "metadata": {
        "id": "9-8C7ogL2Typ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from inference import inference_2d_to_3d \n",
        "\n",
        "generalization_config = {\n",
        "    'experiment_name': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/2d_logs/normal/L2',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'bottleneck': 512,\n",
        "    \"cat\":13,\n",
        "    'batch_size': 32,\n",
        "    \"loss_criterion\":\"L2\",\n",
        "    \"final_layer\":\"normal\",\n",
        "    \"3d_encoder_path\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches/model_epoch_500.pth\",\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    \"autoencoder_bottleneck\":512,\n",
        "    \"autoencoder_hidden_size\":256,\n",
        "    \"autoencoder_output_size\":2048*3\n",
        "\n",
        "}\n",
        "inference_2d_to_3d.main(generalization_config)"
      ],
      "metadata": {
        "id": "4I2gY2Ai2W7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3D Autoencoder Training"
      ],
      "metadata": {
        "id": "Zvw0jND02YKL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "3dU0c36AFxVJ",
        "outputId": "9ca6193c-3a21-400e-ed94-f4d76aa0ef5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " initial input 512 initial hidden 16 initial output 3\n",
            "\u001b[31mBegin Training...\u001b[0m\n",
            "initial point cloud size torch.Size([16, 3, 2048])\n",
            "tensor size after encoder torch.Size([16, 512])\n",
            "tensor size after decoder torch.Size([16, 3])\n",
            "recons size torch.Size([16, 3, 1])\n",
            "point cloud size before loss function torch.Size([16, 2048, 3])\n",
            "recons size before loss function torch.Size([16, 1, 3])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-55adbbeb75b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m }\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrain_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneralization_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/training/train_ae.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recons size before loss function \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchamfer_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m            \u001b[0;31m# optimizer.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/3d-lmnet-pytorch/3d-lmnet-pytorch/utils/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mdists_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mdists_backward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "from training import train_ae\n",
        "\n",
        "\n",
        "    # parser.add_argument(\"--root\", type=str, default=\"./data\")\n",
        "    # parser.add_argument(\"--npoints\", type=int, default=2048)\n",
        "    # parser.add_argument(\"--mpoints\", type=int, default=2025)\n",
        "    # parser.add_argument(\"--batch_size\", type=int, default=16)\n",
        "    # parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
        "    # parser.add_argument(\"--weight_decay\", type=float, default=1e-6)\n",
        "    # parser.add_argument(\"--epochs\", type=int, default=400)\n",
        "    # parser.add_argument(\"--num_workers\", type=int, default=4)\n",
        "    # parser.add_argument(\"--log_dir\", type=str, default=\"./log\")\n",
        "\n",
        "generalization_config = {\n",
        "    'root': './3d-lmnet-pytorch/',\n",
        "    'experiment_name': '3d_autoencoder',\n",
        "    'device': 'cuda:0',  # run this on a gpu for a reasonable training time\n",
        "    'is_overfit': False,\n",
        "    'npoints': 2048,\n",
        "    'mpoints': 2025,\n",
        "    'lr': 1e-4,\n",
        "    \"autoencoder\":\"/content/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches/model_epoch_300.pth\",\n",
        "    'weight_decay': 1e-6,\n",
        "    'bottleneck': 512,\n",
        "    'batch_size': 32,\n",
        "    'resume_ckpt': None,\n",
        "    'learning_rate_model':  0.00005,\n",
        "    'max_epochs': 200,  \n",
        "    'num_workers': 4,\n",
        "    \"input_size\" : 256,\n",
        "    \"hidden_size\" : 256,\n",
        "    \"output_size\" : 2048*3,\n",
        "    'log_dir': '/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/additional_epoches',\n",
        "    'print_every_n': 5,\n",
        "    'visualize_every_n': 5,\n",
        "}\n",
        "\n",
        "train_ae.main(generalization_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3D Inferences"
      ],
      "metadata": {
        "id": "V4LmVnAu2jeS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoaKVSVfgnMc"
      },
      "outputs": [],
      "source": [
        "from inference import infer_3d\n",
        "\n",
        "generalization_config = {\n",
        "    \"autoencoder\":\"/content/drive/MyDrive/3d-lmnet-pytorch/3d-lmnet-pytorch/logs/model_epoch_500.pth\",\n",
        "    'bottleneck': 512,\n",
        "    'batch_size': 1,\n",
        "    'num_workers': 4,\n",
        "    \"input_size\" : 256,\n",
        "    \"hidden_size\" : 256,\n",
        "    \"output_size\" : 2048*3,\n",
        "}\n",
        "\n",
        "infer_3d.main(generalization_config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a453b615765addad4971118d8a9ab96c4ea1423c3e71d4bd1e873af4a20b25f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
